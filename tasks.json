[{"name": "torch", "git": "git@github.com:pytorch/pytorch.git", "questionnaire": [{"type": "def", "name": "none", "docstring": "none", "file": "whatever", "question": "Which folders of my current project do containt python files?"}, {"type": "def", "name": "maybe_mark_dynamic", "docstring": "Mark a tensor as having a dynamic dim, but don't enforce it (i.e., if this\n    dimension ends up getting specialized, don't error).", "file": "./repocloner/pytorch/torch/_dynamo/decorators.py", "question": "Which file contains a function that is used to mark a tensor dimension as dynamic?"}, {"type": "class", "name": "Categorical", "docstring": "Creates a categorical distribution parameterized by either :attr:`probs` or\n    :attr:`logits` (but not both).\n\n    .. note::\n        It is equivalent to the distribution that :func:`torch.multinomial`\n        samples from.\n\n    Samples are integers from :math:`\\{0, \\ldots, K-1\\}` where `K` is ``probs.size(-1)``.\n\n    If `probs` is 1-dimensional with length-`K`, each element is the relative probability\n    of sampling the class at that index.\n\n    If `probs` is N-dimensional, the first N-1 dimensions are treated as a batch of\n    relative probability vectors.\n\n    .. note:: The `probs` argument must be non-negative, finite and have a non-zero sum,\n              and it will be normalized to sum to 1 along the last dimension. :attr:`probs`\n              will return this normalized value.\n              The `logits` argument will be interpreted as unnormalized log probabilities\n              and can therefore be any real number. It will likewise be normalized so that\n              the resulting probabilities sum to 1 along the last dimension. :attr:`logits`\n              will return this normalized value.\n\n    See also: :func:`torch.multinomial`\n\n    Example::\n\n        >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n        >>> m = Categorical(torch.tensor([ 0.25, 0.25, 0.25, 0.25 ]))\n        >>> m.sample()  # equal probability of 0, 1, 2, 3\n        tensor(3)\n\n    Args:\n        probs (Tensor): event probabilities\n        logits (Tensor): event log probabilities (unnormalized)", "file": "./repocloner/pytorch/torch/distributions/categorical.py", "question": "How can I create a categorical distribution with given probabilities or logits using a function?"}, {"type": "def", "name": "debug_draw_graph", "docstring": "Generate an image of the graph for debugging", "file": "./repocloner/pytorch/torch/_inductor/scheduler.py", "question": "What function should I use to generate an image of a graph for debugging purposes?"}, {"type": "def", "name": "resolve_name", "docstring": "Copied from the Cpython implementation of __import__\n        Resolve a relative module name to an absolute one.\n        https://github.com/python/cpython/blob/5a094f0255eea1db58fb2cf14c200971e64ec36e/Lib/importlib/_bootstrap.py#L902", "file": "./repocloner/pytorch/torch/_dynamo/symbolic_convert.py", "question": "Is there a function that resolves a relative module name to an absolute one, similar to CPython\u2019s import?"}, {"type": "class", "name": "FakeTensor", "docstring": "Meta tensors give you the ability to run PyTorch code without having to\n    actually do computation through tensors allocated on a `meta` device.\n    Because the device is `meta`, meta tensors do not model device propagation.\n    FakeTensor extends MetaTensors to also carry an additional `fake_device`\n    which tracks devices that would have been used.", "file": "./repocloner/pytorch/torch/_subclasses/fake_tensor.py", "question": "Which function allows running PyTorch code without actual computation through tensors allocated on a meta device?"}, {"type": "def", "name": "export_stacks", "docstring": "Save stack traces in a file in a format suitable for visualization.\n\n        Args:\n            path (str): save stacks file to this location;\n            metric (str): metric to use: \"self_cpu_time_total\" or \"self_cuda_time_total\"\n\n        .. note::\n            Example of using FlameGraph tool:\n\n            - git clone https://github.com/brendangregg/FlameGraph\n            - cd FlameGraph\n            - ./flamegraph.pl --title \"CPU time\" --countname \"us.\" profiler.stacks > perf_viz.svg", "file": "./repocloner/pytorch/torch/profiler/profiler.py", "question": "What function should I use to save stack traces in a file suitable for visualization?"}, {"type": "class", "name": "Exponential", "docstring": "Creates a Exponential distribution parameterized by :attr:`rate`.\n\n    Example::\n\n        >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n        >>> m = Exponential(torch.tensor([1.0]))\n        >>> m.sample()  # Exponential distributed with rate=1\n        tensor([ 0.1046])\n\n    Args:\n        rate (float or Tensor): rate = 1 / scale of the distribution", "file": "./repocloner/pytorch/torch/distributions/exponential.py", "question": "How do I initialize an Exponential distribution with a specified rate using a function?"}, {"type": "def", "name": "_initial_step", "docstring": "Initialize step counts and performs a step", "file": "./repocloner/pytorch/torch/optim/lr_scheduler.py", "question": "Which function initializes step counts and performs a step?"}, {"type": "def", "name": "get_type", "docstring": "Helper function which converts the given type to a torchScript acceptable format.", "file": "./repocloner/pytorch/torch/jit/_monkeytype_config.py", "question": "Is there a helper function to convert a given type to a torchScript acceptable format?"}, {"type": "def", "name": "reduce_scatter", "docstring": "Reduces, then scatters a list of tensors to all processes in a group.\n\n    Args:\n        output (Tensor): Output tensor.\n        input_list (list[Tensor]): List of tensors to reduce and scatter.\n        op (optional): One of the values from\n            ``torch.distributed.ReduceOp``\n            enum.  Specifies an operation used for element-wise reductions.\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        async_op (bool, optional): Whether this op should be an async op.\n\n    Returns:\n        Async work handle, if async_op is set to True.\n        None, if not async_op or if not part of the group.", "file": "./repocloner/pytorch/torch/distributed/distributed_c10d.py", "question": "Which function can reduce and then scatter a list of tensors to all processes in a group?"}, {"type": "def", "name": "format_all", "docstring": "Bulk version of CapturedTraceback.format.  Returns a list of list of strings.", "file": "./repocloner/pytorch/torch/utils/_traceback.py", "question": "How can I bulk format CapturedTraceback and what will it return?"}, {"type": "def", "name": "_check_mocked_error", "docstring": "checks if an object (field) comes from a mocked module and then adds\n            the pair to mocked_modules which contains mocked modules paired with their\n            list of mocked objects present in the pickle.\n\n            We also hold the invariant that the first user defined rule that applies\n            to the module is the one we use.", "file": "./repocloner/pytorch/torch/package/package_exporter.py", "question": "What function checks if an object comes from a mocked module and adds it to a list of mocked modules and objects?"}, {"type": "class", "name": "LBFGS", "docstring": "Implements L-BFGS algorithm, heavily inspired by `minFunc\n    <https://www.cs.ubc.ca/~schmidtm/Software/minFunc.html>`_.\n\n    .. warning::\n        This optimizer doesn't support per-parameter options and parameter\n        groups (there can be only one).\n\n    .. warning::\n        Right now all parameters have to be on a single device. This will be\n        improved in the future.\n\n    .. note::\n        This is a very memory intensive optimizer (it requires additional\n        ``param_bytes * (history_size + 1)`` bytes). If it doesn't fit in memory\n        try reducing the history size, or use a different algorithm.\n\n    Args:\n        lr (float): learning rate (default: 1)\n        max_iter (int): maximal number of iterations per optimization step\n            (default: 20)\n        max_eval (int): maximal number of function evaluations per optimization\n            step (default: max_iter * 1.25).\n        tolerance_grad (float): termination tolerance on first order optimality\n            (default: 1e-7).\n        tolerance_change (float): termination tolerance on function\n            value/parameter changes (default: 1e-9).\n        history_size (int): update history size (default: 100).\n        line_search_fn (str): either 'strong_wolfe' or None (default: None).", "file": "./repocloner/pytorch/torch/optim/lbfgs.py", "question": "Is there a function implementing the L-BFGS algorithm for optimization?"}, {"type": "def", "name": "probs_to_logits", "docstring": "Converts a tensor of probabilities into logits. For the binary case,\n    this denotes the probability of occurrence of the event indexed by `1`.\n    For the multi-dimensional case, the values along the last dimension\n    denote the probabilities of occurrence of each of the events.", "file": "./repocloner/pytorch/torch/distributions/utils.py", "question": "How can I convert a tensor of probabilities into logits using a function?"}, {"type": "class", "name": "PartialRender", "docstring": "Some parts of a template need to be generated at the end, but\n    inserted into the template at the start.  This allows doing a bunch\n    of replacements after the initial render.", "file": "./repocloner/pytorch/torch/_inductor/select_algorithm.py", "question": "Which function should I use to insert parts of a template at the start after initial render?"}]}, {"name": "numpy", "git": "git@github.com:numpy/numpy.git", "questionnaire": [{"type": "def", "name": "arraylikes", "docstring": "Generator for functions converting an array into various array-likes.\n    If full is True (default) it includes array-likes not capable of handling\n    all dtypes.", "file": "./repocloner/numpy/numpy/_core/tests/test_array_coercion.py", "question": "Function to convert an array into various array-likes."}, {"type": "def", "name": "expandtabs", "docstring": "Return a copy of each string element where all tab characters are\n        replaced by one or more spaces.\n\n        See Also\n        --------\n        char.expandtabs", "file": "./repocloner/numpy/numpy/_core/defchararray.py", "question": "Function to replace tab characters with spaces in strings."}, {"type": "def", "name": "feature_is_exist", "docstring": "Returns True if a certain feature is exist and covered within\n        ``_Config.conf_features``.\n\n        Parameters\n        ----------\n        'name': str\n            feature name in uppercase.", "file": "./repocloner/numpy/numpy/distutils/ccompiler_opt.py", "question": "Function to check if a feature is covered in configuration."}, {"type": "class", "name": "TestAssignValues_1_UCS4", "docstring": "Check the assignment of valued arrays (size 1, UCS4 values)", "file": "./repocloner/numpy/numpy/_core/tests/test_unicode.py", "question": "Function to check assignment of valued arrays with UCS4 values."}, {"type": "def", "name": "roots", "docstring": "Return the roots of the series polynomial.\n\n        Compute the roots for the series. Note that the accuracy of the\n        roots decreases the further outside the `domain` they lie.\n\n        Returns\n        -------\n        roots : ndarray\n            Array containing the roots of the series.", "file": "./repocloner/numpy/numpy/polynomial/_polybase.py", "question": "Function to find roots of a series polynomial."}, {"type": "def", "name": "nancumprod", "docstring": "Return the cumulative product of array elements over a given axis treating Not a\n    Numbers (NaNs) as one.  The cumulative product does not change when NaNs are\n    encountered and leading NaNs are replaced by ones.\n\n    Ones are returned for slices that are all-NaN or empty.\n\n    .. versionadded:: 1.12.0\n\n    Parameters\n    ----------\n    a : array_like\n        Input array.\n    axis : int, optional\n        Axis along which the cumulative product is computed.  By default\n        the input is flattened.\n    dtype : dtype, optional\n        Type of the returned array, as well as of the accumulator in which\n        the elements are multiplied.  If *dtype* is not specified, it\n        defaults to the dtype of `a`, unless `a` has an integer dtype with\n        a precision less than that of the default platform integer.  In\n        that case, the default platform integer is used instead.\n    out : ndarray, optional\n        Alternative output array in which to place the result. It must\n        have the same shape and buffer length as the expected output\n        but the type of the resulting values will be cast if necessary.\n\n    Returns\n    -------\n    nancumprod : ndarray\n        A new array holding the result is returned unless `out` is\n        specified, in which case it is returned.\n\n    See Also\n    --------\n    numpy.cumprod : Cumulative product across array propagating NaNs.\n    isnan : Show which elements are NaN.\n\n    Examples\n    --------\n    >>> np.nancumprod(1)\n    array([1])\n    >>> np.nancumprod([1])\n    array([1])\n    >>> np.nancumprod([1, np.nan])\n    array([1.,  1.])\n    >>> a = np.array([[1, 2], [3, np.nan]])\n    >>> np.nancumprod(a)\n    array([1.,  2.,  6.,  6.])\n    >>> np.nancumprod(a, axis=0)\n    array([[1.,  2.],\n           [3.,  2.]])\n    >>> np.nancumprod(a, axis=1)\n    array([[1.,  2.],\n           [3.,  3.]])", "file": "./repocloner/numpy/numpy/lib/_nanfunctions_impl.py", "question": "Function to return cumulative product treating NaNs as ones."}, {"type": "def", "name": "_fieldmask", "docstring": "Alias to mask.", "file": "./repocloner/numpy/numpy/ma/mrecords.py", "question": "Function that is an alias to mask."}, {"type": "def", "name": "find", "docstring": "For each element, return the lowest index in the string where\n    substring `sub` is found.\n\n    Calls :meth:`str.find` element-wise.\n\n    For each element, return the lowest index in the string where\n    substring `sub` is found, such that `sub` is contained in the\n    range [`start`, `end`].\n\n    Parameters\n    ----------\n    a : array_like of str or unicode\n\n    sub : str or unicode\n\n    start, end : int, optional\n        Optional arguments `start` and `end` are interpreted as in\n        slice notation.\n\n    Returns\n    -------\n    out : ndarray or int\n        Output array of ints.  Returns -1 if `sub` is not found.\n\n    See Also\n    --------\n    str.find\n\n    Examples\n    --------\n    >>> a = np.array([\"NumPy is a Python library\"])\n    >>> np.char.find(a, \"Python\", start=0, end=None)\n    array([11])", "file": "./repocloner/numpy/numpy/_core/defchararray.py", "question": "Function to find the index of a substring in strings of an array."}, {"type": "def", "name": "deprecate_with_doc", "docstring": "Deprecates a function and includes the deprecation in its docstring.\n\n    .. deprecated:: 2.0\n        Use `~warnings.warn` with :exc:`DeprecationWarning` instead.\n\n    This function is used as a decorator. It returns an object that can be\n    used to issue a DeprecationWarning, by passing the to-be decorated\n    function as argument, this adds warning to the to-be decorated function's\n    docstring and returns the new function object.\n\n    See Also\n    --------\n    deprecate : Decorate a function such that it issues a `DeprecationWarning`\n\n    Parameters\n    ----------\n    msg : str\n        Additional explanation of the deprecation. Displayed in the\n        docstring after the warning.\n\n    Returns\n    -------\n    obj : object", "file": "./repocloner/numpy/numpy/lib/_utils_impl.py", "question": "Function to deprecate another function and include the deprecation in its docstring."}, {"type": "def", "name": "recursive_fill_fields", "docstring": "Fills fields from output with fields from input,\n    with support for nested structures.\n\n    Parameters\n    ----------\n    input : ndarray\n        Input array.\n    output : ndarray\n        Output array.\n\n    Notes\n    -----\n    * `output` should be at least the same size as `input`\n\n    Examples\n    --------\n    >>> from numpy.lib import recfunctions as rfn\n    >>> a = np.array([(1, 10.), (2, 20.)], dtype=[('A', np.int64), ('B', np.float64)])\n    >>> b = np.zeros((3,), dtype=a.dtype)\n    >>> rfn.recursive_fill_fields(a, b)\n    array([(1, 10.), (2, 20.), (0,  0.)], dtype=[('A', '<i8'), ('B', '<f8')])", "file": "./repocloner/numpy/numpy/lib/recfunctions.py", "question": "Function to fill fields in output array from fields in input array."}, {"type": "def", "name": "nanargmax", "docstring": "Return the indices of the maximum values in the specified axis ignoring\n    NaNs. For all-NaN slices ``ValueError`` is raised. Warning: the\n    results cannot be trusted if a slice contains only NaNs and -Infs.\n\n\n    Parameters\n    ----------\n    a : array_like\n        Input data.\n    axis : int, optional\n        Axis along which to operate.  By default flattened input is used.\n    out : array, optional\n        If provided, the result will be inserted into this array. It should\n        be of the appropriate shape and dtype.\n\n        .. versionadded:: 1.22.0\n    keepdims : bool, optional\n        If this is set to True, the axes which are reduced are left\n        in the result as dimensions with size one. With this option,\n        the result will broadcast correctly against the array.\n\n        .. versionadded:: 1.22.0\n\n    Returns\n    -------\n    index_array : ndarray\n        An array of indices or a single index value.\n\n    See Also\n    --------\n    argmax, nanargmin\n\n    Examples\n    --------\n    >>> a = np.array([[np.nan, 4], [2, 3]])\n    >>> np.argmax(a)\n    0\n    >>> np.nanargmax(a)\n    1\n    >>> np.nanargmax(a, axis=0)\n    array([1, 0])\n    >>> np.nanargmax(a, axis=1)\n    array([1, 1])", "file": "./repocloner/numpy/numpy/lib/_nanfunctions_impl.py", "question": "Function to return indices of maximum values ignoring NaNs."}, {"type": "def", "name": "_vectorize_call", "docstring": "Vectorized call to `func` over positional `args`.", "file": "./repocloner/numpy/numpy/lib/_function_base_impl.py", "question": "Function for vectorized call to another function over its arguments."}, {"type": "class", "name": "InstallableLib", "docstring": "Container to hold information on an installable library.\n\n    Parameters\n    ----------\n    name : str\n        Name of the installed library.\n    build_info : dict\n        Dictionary holding build information.\n    target_dir : str\n        Absolute path specifying where to install the library.\n\n    See Also\n    --------\n    Configuration.add_installed_library\n\n    Notes\n    -----\n    The three parameters are stored as attributes with the same names.", "file": "./repocloner/numpy/numpy/distutils/misc_util.py", "question": "Function or container to hold information on an installable library."}, {"type": "def", "name": "in1d", "docstring": "Test whether each element of an array is also present in a second\n    array.\n\n    The output is always a masked array. See `numpy.in1d` for more details.\n\n    We recommend using :func:`isin` instead of `in1d` for new code.\n\n    See Also\n    --------\n    isin       : Version of this function that preserves the shape of ar1.\n    numpy.in1d : Equivalent function for ndarrays.\n\n    Notes\n    -----\n    .. versionadded:: 1.4.0", "file": "./repocloner/numpy/numpy/ma/extras.py", "question": "Function to test if elements of one array are present in another array."}, {"type": "def", "name": "test_debugcapi", "docstring": "Ensures that debugging wrappers are written\n\n    CLI :: --debug-capi", "file": "./repocloner/numpy/numpy/f2py/tests/test_f2py2e.py", "question": "Function to ensure that debugging wrappers are written for C API."}]}]